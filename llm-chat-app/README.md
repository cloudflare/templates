# LLM Chat Application Template

A simple, ready-to-deploy chat application template powered by Cloudflare Workers AI. This template provides a clean starting point for building AI chat applications with streaming responses.

<!-- dash-content-start -->
## Demo

This template demonstrates how to build a chat interface using Cloudflare Workers AI. It combines Workers for backend processing with the Workers AI binding to create an interactive streaming chat experience.
<!-- dash-content-end -->

## Features

- ğŸ’¬ Simple and responsive chat interface
- âš¡ Server-Sent Events (SSE) for streaming responses
- ğŸ§  Powered by Cloudflare Workers AI LLMs
- ğŸ› ï¸ Built with TypeScript and Cloudflare Workers
- ğŸ“± Mobile-friendly design
- ğŸ”„ Maintains chat history on the client

## Getting Started

### Prerequisites

- [Node.js](https://nodejs.org/) (v18 or newer)
- [Wrangler CLI](https://developers.cloudflare.com/workers/wrangler/install-and-update/)
- A Cloudflare account with Workers AI access

### Installation

1. Clone this repository:
   ```bash
   git clone https://github.com/cloudflare/templates.git
   cd templates/llm-chat-app
   ```

2. Install dependencies:
   ```bash
   npm install
   ```

3. Generate Worker type definitions:
   ```bash
   npm run cf-typegen
   ```

### Development

Start a local development server:
```bash
npm run dev
```

This will start a local server at http://localhost:8787.

Note: Using Workers AI accesses your Cloudflare account even during local development, which will incur usage charges.

### Deployment

Deploy to Cloudflare Workers:
```bash
npm run deploy
```

## Project Structure

```
/
â”œâ”€â”€ public/             # Static assets
â”‚   â”œâ”€â”€ index.html      # Chat UI HTML
â”‚   â””â”€â”€ chat.js         # Chat UI frontend script
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts        # Main Worker entry point
â”‚   â””â”€â”€ types.ts        # TypeScript type definitions
â”œâ”€â”€ test/               # Test files
â”œâ”€â”€ wrangler.jsonc      # Cloudflare Worker configuration
â”œâ”€â”€ tsconfig.json       # TypeScript configuration
â””â”€â”€ README.md           # This documentation
```

## How It Works

### Backend

The backend is built with Cloudflare Workers and uses the Workers AI platform to generate responses. The main components are:

1. **API Endpoint** (`/api/chat`): Accepts POST requests with chat messages and streams responses
2. **Streaming**: Uses Server-Sent Events (SSE) for real-time streaming of AI responses
3. **Workers AI Binding**: Connects to Cloudflare's AI service via the Workers AI binding

### Frontend

The frontend is a simple HTML/CSS/JavaScript application that:

1. Presents a chat interface
2. Sends user messages to the API
3. Processes streaming responses in real-time
4. Maintains chat history on the client side

## Customization

### Changing the Model

To use a different AI model, update the `MODEL_ID` constant in `src/index.ts`. You can find available models in the [Cloudflare Workers AI documentation](https://developers.cloudflare.com/workers-ai/models/).

### Using AI Gateway

The template includes commented code for AI Gateway integration. To use AI Gateway:

1. Uncomment the gateway configuration in `src/index.ts`
2. Replace `YOUR_GATEWAY_ID` with your actual AI Gateway ID
3. Configure other gateway options as needed

Learn more about [AI Gateway](https://developers.cloudflare.com/ai-gateway/).

### Modifying the System Prompt

The default system prompt can be changed by updating the `SYSTEM_PROMPT` constant in `src/index.ts`.

### Styling

The UI styling is contained in the `<style>` section of `public/index.html`. You can modify the CSS variables at the top to quickly change the color scheme.

## Resources

- [Cloudflare Workers Documentation](https://developers.cloudflare.com/workers/)
- [Cloudflare Workers AI Documentation](https://developers.cloudflare.com/workers-ai/)
- [Workers AI Models](https://developers.cloudflare.com/workers-ai/models/)